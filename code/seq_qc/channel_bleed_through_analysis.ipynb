{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate channel bleed-through based on seq_qc data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an example in the starfish [BaristaSeq pipeline](https://spacetx-starfish.readthedocs.io/en/latest/gallery/pipelines/baristaseq_pipeline.html?highlight=registration#correct-for-bleed-through-from-illumina-sbs-reagents), with the method described in [Chen et al. 2017](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5829746/).\n",
    "\n",
    "In order to estimate the bleed-through per channel, we use the first round of the AGTC test data after background filtering with a WhiteTophat filter.\n",
    "\n",
    "In each of the experiments, only one of the four channels should have signal in the first round. Signal in all other channels is spurious. This is generally also true for later rounds. However, we expect some degree of imperfect incorporation and cleavage in the sequencing. Therefore, there might be true signal in other channels in later rounds.\n",
    "\n",
    "Bleed-through factors for linear unmixing are estimated using Lasso regression as in [RoysamLab/whole_brain_analysis](https://github.com/RoysamLab/whole_brain_analysis) ([Maric et al. 2021](https://www.nature.com/articles/s41467-021-21735-x)).\n",
    "\n",
    "Note: more sophisticated methods for bleed-through estimation exist but are not necessary in our case (e.g. [Theia by Ishaq et al. 2022](https://doi.org/10.1109/ISBI52829.2022.9761410))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from starfish import Experiment\n",
    "from starfish.image import Filter\n",
    "from starfish.types import Axes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "masking_radius = 6\n",
    "filt = Filter.WhiteTophat(masking_radius, is_volume=False)\n",
    "# now use it like this:\n",
    "#filtered = filt.run(imgs, verbose=False, in_place=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel bleed-through estimation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the implementation in [RoysamLab/whole_brain_analysis:inter_channel_correction.py](https://github.com/RoysamLab/whole_brain_analysis/blob/7626c59d8696c5c80d4c8c5ac3f81c0e8170cb7f/RECONSTRUCTION/inter_channel_correction.py#L77-L96)\n",
    "\n",
    "<details>\n",
    "\n",
    "```python\n",
    "def calculate_unmixing_params_unsupervised(images):\n",
    "    # convert to float\n",
    "    images = img_as_float(images)\n",
    "    num_channels = images.shape[2]\n",
    "\n",
    "    # make a list to keep result parameters\n",
    "    results = np.zeros((num_channels, num_channels))\n",
    "\n",
    "    # for all channels\n",
    "    for i in range(num_channels):\n",
    "        endmembers = [np.ndarray.flatten(images[:, :, idx]) for idx in range(num_channels)]\n",
    "        source = endmembers.pop(i)\n",
    "\n",
    "        clf = linear_model.Lasso(alpha=.0001, copy_X=True, positive=True)\n",
    "        clf.fit(np.array(endmembers).T, source)\n",
    "        alphas = np.insert(clf.coef_, i, 0)\n",
    "\n",
    "        results[i, :] = alphas\n",
    "\n",
    "    return results\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disclaimer: this value for the lasso alpha was chosen after experimentation with different values\n",
    "lasso_alpha = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 129.67it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 137.31it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 136.50it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 144.98it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 145.04it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 142.35it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 144.28it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 138.08it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 142.72it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 153.14it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 140.60it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 149.38it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 153.79it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 132.02it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 137.44it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 135.31it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 138.28it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 127.06it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 116.91it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 132.98it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 130.85it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 125.77it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 127.44it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 132.56it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 128.04it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 151.49it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 134.73it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 139.99it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 121.33it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 134.52it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 146.79it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 138.35it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 123.30it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 131.69it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 126.90it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 141.28it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 126.75it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 144.02it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 138.48it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 131.98it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 137.36it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 120.86it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 146.10it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 133.81it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 139.47it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 156.51it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 134.04it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 147.78it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 142.21it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 130.64it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 139.96it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 134.28it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 136.97it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 149.54it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 146.68it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 143.03it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 132.80it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 132.68it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 102.16it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 142.53it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 136.69it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 148.00it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 141.07it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 128.38it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for sample, sources in zip([\"A_PB2\", \"C_PB1\", \"G_PA\", \"T_HA\"], [[0,1,3,2,1,3], [3,1], [1,1], [2,0]]):\n",
    "\texp = Experiment.from_json(os.path.join(\"data/spacetx/seq_qc/rep0/\", sample, \"experiment.json\"))\n",
    "\tfor fov in exp.fovs():\n",
    "\t\timgs = fov.get_image(\"primary\")\n",
    "\t\t# remove background with WhiteTophat filter\n",
    "\t\tfilt.run(imgs, verbose=False, in_place=True)\n",
    "\t\tfor round, source_channel in enumerate(sources):\n",
    "\t\t\tendmembers = [(1/imgs.xarray.max().item())*imgs.sel({Axes.ROUND: round}).xarray[0,idx,0].to_numpy().flatten() for idx in range(4)]\n",
    "\t\t\tsource = endmembers.pop(source_channel)\n",
    "\t\t\tclf = linear_model.Lasso(alpha=lasso_alpha, copy_X=True, positive=True)\n",
    "\t\t\t#clf = linear_model.LinearRegression(copy_X=True, positive=True)\n",
    "\t\t\tclf.fit(np.array(endmembers).T, source)\n",
    "\t\t\talphas = np.insert(clf.coef_, source_channel, 0)\n",
    "\t\t\t# print(\"AGTC\"[source_channel], alphas)\n",
    "\t\t\tresults.append({\"sample\": sample, \"fov\": fov.name, \"round\": round, \"source\": \"AGTC\"[source_channel], **dict(zip(\"AGTC\", alphas))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"analysis/bleed_through\", exist_ok=True)\n",
    "values = pd.DataFrame.from_records(results)\n",
    "values.to_csv(\"analysis/bleed_through/lasso_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated bleed-through factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655722</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A    G         T    C\n",
       "source                         \n",
       "A       0.0  0.0  0.655722  0.0\n",
       "C       0.0  0.0  0.000000  0.0\n",
       "G       0.0  0.0  0.000000  0.0\n",
       "T       0.0  0.0  0.000000  0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[values[\"round\"] == 0].groupby(\"source\")[[\"A\",\"G\",\"T\",\"C\"]].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bleed-through correction: linear unmixing\n",
    "\n",
    "Starfish provides a method to correct for channel bleed-through via linear unmixing.\n",
    "The coefficient matrix based on the results above (given the channel order \"AGTC\") is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleed = np.array(\n",
    "    [[ 1.  ,  0.  , -0.656,  0.  ],\n",
    "     [ 0.  ,  1.  ,  0.   ,  0.  ],\n",
    "     [ 0.  ,  0.  ,  1.   ,  0.  ],\n",
    "     [ 0.  ,  0.  ,  0.   ,  1.  ]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lum = Filter.LinearUnmixing(bleed)\n",
    "# now use it like this:\n",
    "#bleed_corrected = lum.run(filtered, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that bleed-through from A to T is reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load example fov from A_PB2 experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_coefficients(data, round, source_channel):\n",
    "    endmembers = [(1/data.xarray.max().item())*data.sel({Axes.ROUND: round}).xarray[0,idx,0].to_numpy().flatten() for idx in range(4)]\n",
    "    source = endmembers.pop(source_channel)\n",
    "    clf = linear_model.Lasso(alpha=lasso_alpha, copy_X=True, positive=True)\n",
    "    #clf = linear_model.LinearRegression(copy_X=True, positive=True)\n",
    "    clf.fit(np.array(endmembers).T, source)\n",
    "    alphas = np.insert(clf.coef_, source_channel, 0)\n",
    "    return alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 166.43it/s]\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment.from_json(os.path.join(\"data/spacetx/seq_qc/rep0/\", \"A_PB2\", \"experiment.json\"))\n",
    "fov = exp.fovs()[2]\n",
    "imgs = fov.get_image(\"primary\")\n",
    "filtered = filt.run(imgs, verbose=False, in_place=False)\n",
    "bleed_corrected = lum.run(filtered, in_place=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 59.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw:\t[0.       0.       7.089077 0.      ]\n",
      "filtered:\t[0.       0.       0.603057 0.      ]\n",
      "corrected:\t[0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"raw:\", estimate_coefficients(imgs, 0, 0), sep=\"\\t\")\n",
    "print(\"filtered:\", estimate_coefficients(filtered, 0, 0), sep=\"\\t\")\n",
    "print(\"corrected:\", estimate_coefficients(bleed_corrected, 0, 0), sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba368e385c9cc9598b2a60a5e4fac7f72009cf9cbc64180bf4bd906d7f9b6ec6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
